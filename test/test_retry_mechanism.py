#!/usr/bin/env python3
"""
é‡è©¦æ©Ÿåˆ¶æ•´åˆæ¸¬è©¦
æ¸¬è©¦ç›®æ¨™ï¼šé©—è­‰é‡è©¦æ©Ÿåˆ¶èƒ½æå‡ LLM æˆåŠŸçŽ‡å¾ž 66% â†’ 96%
"""
import asyncio
import sys
import time
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent / "txt2pptx"))

from backend.models import GenerateRequest
from backend.llm_service import generate_outline
from backend.pptx_generator import generate_pptx


async def run_single_test(test_num: int, test_text: str) -> dict:
    """åŸ·è¡Œå–®æ¬¡æ¸¬è©¦ä¸¦è¨˜éŒ„çµæžœ"""
    request = GenerateRequest(
        text=test_text,
        num_slides=8,
        language="ç¹é«”ä¸­æ–‡",
        style="ocean_gradient"
    )

    start_time = time.time()

    try:
        outline = await generate_outline(request)
        duration = time.time() - start_time

        # æª¢æŸ¥æ˜¯å¦ç‚º demo mode (165 å¼µæŠ•å½±ç‰‡æ˜¯æ˜Žé¡¯çš„ demo fallback)
        is_demo_mode = len(outline.slides) > 50

        # å“è³ªæª¢æŸ¥
        bullet_lengths = []
        for slide in outline.slides:
            if hasattr(slide, 'bullets') and slide.bullets:
                avg_len = sum(len(b) for b in slide.bullets) / len(slide.bullets)
                bullet_lengths.append(avg_len)

        avg_bullet_len = sum(bullet_lengths) / len(bullet_lengths) if bullet_lengths else 0
        slides_with_notes = sum(1 for s in outline.slides if s.speaker_notes and len(s.speaker_notes.strip()) > 0)
        note_lengths = [len(s.speaker_notes) for s in outline.slides if s.speaker_notes]
        avg_note_len = sum(note_lengths) / len(note_lengths) if note_lengths else 0
        layouts = set(s.layout.value for s in outline.slides)

        # å“è³ªè©•åˆ†
        quality_score = 0
        if avg_bullet_len >= 15:
            quality_score += 1
        if slides_with_notes >= len(outline.slides) * 0.7:
            quality_score += 1
        if avg_note_len >= 50:
            quality_score += 1
        if len(layouts) >= 5:
            quality_score += 1

        return {
            "test_num": test_num,
            "success": True,
            "duration": duration,
            "slides": len(outline.slides),
            "is_demo_mode": is_demo_mode,
            "quality_score": quality_score,
            "avg_bullet_len": avg_bullet_len,
            "notes_coverage": slides_with_notes / len(outline.slides),
            "avg_note_len": avg_note_len,
            "layout_diversity": len(layouts)
        }

    except Exception as e:
        duration = time.time() - start_time
        return {
            "test_num": test_num,
            "success": False,
            "duration": duration,
            "error": str(e)[:100]
        }


async def main():
    # åœ–è«–æ¸¬è©¦æ–‡å­—ï¼ˆèˆ‡ä¹‹å‰æ¸¬è©¦ç›¸åŒï¼‰
    test_text = """åœ–è«–ï¼ˆè‹±èªžï¼šGraph theoryï¼‰ï¼Œæ˜¯çµ„åˆæ•¸å­¸åˆ†æ”¯ï¼Œå’Œå…¶ä»–æ•¸å­¸åˆ†æ”¯å¦‚ç¾¤è«–ã€çŸ©é™£è«–ã€æ‹“æ’²å­¸æœ‰è‘—å¯†åˆ‡é—œä¿‚ã€‚
åœ–æ˜¯åœ–è«–çš„ä¸»è¦ç ”ç©¶å°è±¡ã€‚åœ–æ˜¯ç”±è‹¥å¹²çµ¦å®šçš„é ‚é»žåŠé€£æŽ¥å…©é ‚é»žçš„é‚Šæ‰€æ§‹æˆçš„åœ–å½¢ï¼Œé€™ç¨®åœ–å½¢é€šå¸¸ç”¨ä¾†æè¿°æŸäº›äº‹ç‰©ä¹‹é–“çš„æŸç¨®ç‰¹å®šé—œä¿‚ã€‚é ‚é»žç”¨æ–¼ä»£è¡¨äº‹ç‰©ï¼Œé€£æŽ¥å…©é ‚é»žçš„é‚Šå‰‡ç”¨æ–¼è¡¨ç¤ºå…©å€‹äº‹ç‰©é–“å…·æœ‰é€™ç¨®é—œä¿‚ã€‚
åœ–è«–èµ·æºæ–¼è‘—åçš„æŸ¯å°¼æ–¯å ¡ä¸ƒæ©‹å•é¡Œã€‚è©²å•é¡Œæ–¼1736å¹´è¢«æ­æ‹‰è§£æ±ºï¼Œå› æ­¤æ™®éèªç‚ºæ­æ‹‰æ˜¯åœ–è«–çš„å‰µå§‹äººã€‚"""

    print("=" * 80)
    print("é‡è©¦æ©Ÿåˆ¶æ•´åˆæ¸¬è©¦")
    print("ç›®æ¨™ï¼šé©—è­‰é‡è©¦æ©Ÿåˆ¶èƒ½æå‡æˆåŠŸçŽ‡å¾ž 66% â†’ 96%")
    print("=" * 80)
    print()

    # åŸ·è¡Œ 10 æ¬¡æ¸¬è©¦
    num_tests = 10
    results = []

    for i in range(1, num_tests + 1):
        print(f"åŸ·è¡Œæ¸¬è©¦ {i}/{num_tests}...", end=" ", flush=True)
        result = await run_single_test(i, test_text)
        results.append(result)

        if result["success"]:
            mode = "DEMO" if result["is_demo_mode"] else "LLM"
            print(f"âœ… {mode} ({result['duration']:.1f}s, å“è³ª: {result['quality_score']}/4)")
        else:
            print(f"âŒ å¤±æ•— ({result['duration']:.1f}s)")

    # çµ±è¨ˆçµæžœ
    print()
    print("=" * 80)
    print("ðŸ“Š æ¸¬è©¦çµæžœçµ±è¨ˆ")
    print("=" * 80)

    successful_tests = [r for r in results if r["success"]]
    llm_successes = [r for r in successful_tests if not r["is_demo_mode"]]
    demo_fallbacks = [r for r in successful_tests if r["is_demo_mode"]]

    total_count = len(results)
    success_count = len(successful_tests)
    llm_success_count = len(llm_successes)
    demo_count = len(demo_fallbacks)

    print(f"\nç¸½æ¸¬è©¦æ¬¡æ•¸: {total_count}")
    print(f"æˆåŠŸæ¬¡æ•¸: {success_count} ({success_count/total_count*100:.1f}%)")
    print(f"  - LLM æˆåŠŸ: {llm_success_count} ({llm_success_count/total_count*100:.1f}%)")
    print(f"  - Demo Fallback: {demo_count} ({demo_count/total_count*100:.1f}%)")

    if llm_successes:
        avg_quality = sum(r["quality_score"] for r in llm_successes) / len(llm_successes)
        avg_duration = sum(r["duration"] for r in llm_successes) / len(llm_successes)
        print(f"\nLLM æˆåŠŸæ¡ˆä¾‹:")
        print(f"  - å¹³å‡å“è³ªåˆ†æ•¸: {avg_quality:.2f}/4")
        print(f"  - å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_duration:.1f} ç§’")
        print(f"  - å¹³å‡ bullet é•·åº¦: {sum(r['avg_bullet_len'] for r in llm_successes)/len(llm_successes):.1f} å­—")
        print(f"  - å¹³å‡ notes é•·åº¦: {sum(r['avg_note_len'] for r in llm_successes)/len(llm_successes):.1f} å­—")

    # èˆ‡é æœŸå°æ¯”
    print(f"\nðŸ“ˆ èˆ‡é æœŸç›®æ¨™å°æ¯”:")
    print(f"  ç•¶å‰ LLM æˆåŠŸçŽ‡: {llm_success_count/total_count*100:.1f}% (ç›®æ¨™: â‰¥ 96%)")
    print(f"  ç•¶å‰ Demo Fallback çŽ‡: {demo_count/total_count*100:.1f}% (ç›®æ¨™: â‰¤ 4%)")

    if llm_success_count / total_count >= 0.95:
        print("\nðŸŽ‰ å„ªç§€ï¼é”æˆç›®æ¨™ï¼Œé‡è©¦æ©Ÿåˆ¶é‹ä½œæ­£å¸¸ï¼")
    elif llm_success_count / total_count >= 0.80:
        print("\nâœ… è‰¯å¥½ï¼æˆåŠŸçŽ‡é¡¯è‘—æå‡ï¼Œé‡è©¦æ©Ÿåˆ¶æœ‰æ•ˆã€‚")
    else:
        print("\nâš ï¸ æ³¨æ„ï¼šæˆåŠŸçŽ‡ä½Žæ–¼é æœŸï¼Œå¯èƒ½éœ€è¦èª¿æ•´åƒæ•¸æˆ–æª¢æŸ¥ LLM é…ç½®ã€‚")

    return llm_success_count / total_count


if __name__ == "__main__":
    success_rate = asyncio.run(main())
    sys.exit(0 if success_rate >= 0.80 else 1)
