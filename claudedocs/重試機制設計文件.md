# é‡è©¦æ©Ÿåˆ¶ï¼ˆRetry Mechanismï¼‰è¨­è¨ˆæ–‡ä»¶

## æ–‡ä»¶è³‡è¨Š

- **å‰µå»ºæ—¥æœŸ**ï¼š2026-02-17
- **ç‰ˆæœ¬**ï¼š1.0
- **ç›®çš„**ï¼šæå‡ LLM èª¿ç”¨çš„ç©©å®šæ€§å’ŒæˆåŠŸç‡
- **ç›¸é—œæ–‡ä»¶**ï¼š[JSON_vs_Markdown_åˆ†æçµæœ.md](JSON_vs_Markdown_åˆ†æçµæœ.md)

---

## æ¦‚è¿°

### ä»€éº¼æ˜¯é‡è©¦æ©Ÿåˆ¶ï¼Ÿ

**é‡è©¦æ©Ÿåˆ¶**ï¼ˆRetry Mechanismï¼‰æ˜¯ä¸€ç¨®å®¹éŒ¯æŠ€è¡“ï¼Œç•¶æ“ä½œå¤±æ•—æ™‚ï¼Œè‡ªå‹•é‡æ–°å˜—è©¦è©²æ“ä½œè‹¥å¹²æ¬¡ï¼Œè€Œä¸æ˜¯ç«‹å³æ”¾æ£„ã€‚

### ç‚ºä»€éº¼éœ€è¦é‡è©¦ï¼Ÿ

**ç•¶å‰å•é¡Œ**ï¼š
- LLM èª¿ç”¨æœ‰ç´„ 33% çš„å¤±æ•—ç‡
- å¤±æ•—ä¸€æ¬¡å°±ç«‹å³å›é€€åˆ° demo mode
- å°è‡´ç”¨æˆ¶é«”é©—ä¸ç©©å®š

**æ ¸å¿ƒç›®æ¨™**ï¼š
- æå‡ LLM æˆåŠŸç‡å¾ 66% â†’ **96%**
- æ¸›å°‘ demo fallback ç™¼ç”Ÿç‡å¾ 34% â†’ **3.6%**
- æä¾›æ›´ç©©å®šçš„ç”¨æˆ¶é«”é©—

---

## æ•¸å­¸åŸç†

### æ¦‚ç‡è¨ˆç®—

**åŸºæœ¬å‡è¨­**ï¼š
- å–®æ¬¡ LLM èª¿ç”¨æˆåŠŸç‡ï¼šP(æˆåŠŸ) = 0.66
- å–®æ¬¡ LLM èª¿ç”¨å¤±æ•—ç‡ï¼šP(å¤±æ•—) = 0.34

**é‡è©¦ N æ¬¡å¾Œçš„æˆåŠŸç‡**ï¼š
```
P(è‡³å°‘ä¸€æ¬¡æˆåŠŸ) = 1 - P(é€£çºŒ N æ¬¡éƒ½å¤±æ•—)
                = 1 - (0.34)^N
```

### æˆåŠŸç‡å°æ¯”è¡¨

| å˜—è©¦æ¬¡æ•¸ | è¨ˆç®—å…¬å¼ | æˆåŠŸç‡ | Demo Fallback ç‡ | æå‡å¹…åº¦ |
|---------|---------|--------|------------------|---------|
| 1 æ¬¡ï¼ˆç•¶å‰ï¼‰ | 1 - 0.34Â¹ | **66.0%** | 34.0% | åŸºç·š |
| 2 æ¬¡ | 1 - 0.34Â² | **88.4%** | 11.6% | +22.4% |
| **3 æ¬¡ï¼ˆæ¨è–¦ï¼‰** | 1 - 0.34Â³ | **96.1%** | 3.9% | **+30.1%** |
| 4 æ¬¡ | 1 - 0.34â´ | **98.7%** | 1.3% | +32.7% |
| 5 æ¬¡ | 1 - 0.34âµ | **99.6%** | 0.4% | +33.6% |

**æœ€ä½³å¹³è¡¡é»**ï¼š3 æ¬¡é‡è©¦
- âœ… æˆåŠŸç‡æå‡é¡¯è‘—ï¼ˆ+30.1%ï¼‰
- âœ… éŸ¿æ‡‰æ™‚é–“å¯æ¥å—ï¼ˆæœ€å¤šå»¶é² 6 ç§’ï¼‰
- âœ… è³‡æºæ¶ˆè€—åˆç†

---

## è¨­è¨ˆæ–¹æ¡ˆ

### æ–¹æ¡ˆ Aï¼šç°¡å–®é‡è©¦ï¼ˆæ¨è–¦ï¼‰

**ç‰¹é»**ï¼š
- å›ºå®šç­‰å¾…æ™‚é–“ï¼ˆ1 ç§’ï¼‰
- æœ€å¤šé‡è©¦ 3 æ¬¡
- å¯¦ä½œç°¡å–®

**å„ªé»**ï¼š
- âœ… ä»£ç¢¼ç°¡æ½”æ˜“æ‡‚
- âœ… è¡Œç‚ºå¯é æ¸¬
- âœ… è³‡æºæ¶ˆè€—ä½

**ç¼ºé»**ï¼š
- âŒ ç­‰å¾…æ™‚é–“å›ºå®šï¼Œä¸é©æ‡‰è² è¼‰è®ŠåŒ–

**é©ç”¨å ´æ™¯**ï¼š
- ä¸€èˆ¬æ‡‰ç”¨å ´æ™¯
- LLM æœå‹™è² è¼‰ç©©å®š
- å¿«é€Ÿå¯¦ä½œéœ€æ±‚

---

### æ–¹æ¡ˆ Bï¼šæŒ‡æ•¸é€€é¿ï¼ˆå¯é¸ï¼‰

**ç‰¹é»**ï¼š
- ç­‰å¾…æ™‚é–“éå¢ï¼š1 ç§’ã€2 ç§’ã€4 ç§’
- é©æ‡‰æœå‹™å™¨è² è¼‰æƒ…æ³
- é¿å…é€£çºŒå¿«é€Ÿè«‹æ±‚

**å„ªé»**ï¼š
- âœ… å°æœå‹™å™¨æ›´å‹å¥½
- âœ… é©æ‡‰é«˜è² è¼‰å ´æ™¯
- âœ… æ¸›å°‘é€£çºŒå¤±æ•—æ¦‚ç‡

**ç¼ºé»**ï¼š
- âŒ æœ€å£æƒ…æ³éŸ¿æ‡‰æ™‚é–“æ›´é•·ï¼ˆ7 ç§’ vs 6 ç§’ï¼‰
- âŒ å¯¦ä½œç¨è¤‡é›œ

**é©ç”¨å ´æ™¯**ï¼š
- æœå‹™å™¨è² è¼‰æ³¢å‹•å¤§
- éœ€è¦æ›´å„ªé›…çš„éŒ¯èª¤è™•ç†
- ç”Ÿç”¢ç’°å¢ƒé«˜å¯ç”¨éœ€æ±‚

---

### æ–¹æ¡ˆ Cï¼šæ™ºèƒ½é‡è©¦ï¼ˆé€²éšï¼‰

**ç‰¹é»**ï¼š
- æ ¹æ“šéŒ¯èª¤é¡å‹æ±ºå®šæ˜¯å¦é‡è©¦
- æŸäº›éŒ¯èª¤ä¸é‡è©¦ï¼ˆå¦‚é©—è­‰éŒ¯èª¤ï¼‰
- åƒ…é‡è©¦æš«æ™‚æ€§éŒ¯èª¤ï¼ˆç¶²çµ¡ã€è¶…æ™‚ï¼‰

**å„ªé»**ï¼š
- âœ… æ›´é«˜æ•ˆï¼Œé¿å…ç„¡æ„ç¾©é‡è©¦
- âœ… éŒ¯èª¤è™•ç†æ›´ç²¾ç´°
- âœ… ç¯€çœè³‡æº

**ç¼ºé»**ï¼š
- âŒ éœ€è¦è©³ç´°éŒ¯èª¤åˆ†é¡
- âŒ å¯¦ä½œè¤‡é›œåº¦é«˜
- âŒ ç¶­è­·æˆæœ¬é«˜

**é©ç”¨å ´æ™¯**ï¼š
- å¤§è¦æ¨¡ç”Ÿç”¢ç’°å¢ƒ
- æˆæœ¬æ•æ„Ÿå ´æ™¯
- éœ€è¦ç´°ç²’åº¦æ§åˆ¶

---

## å¯¦ä½œè¨­è¨ˆ

### ç•¶å‰ä»£ç¢¼ï¼ˆç„¡é‡è©¦ï¼‰

**ä½ç½®**ï¼š`txt2pptx/backend/llm_service.py` L287-300

```python
async def generate_outline(request: GenerateRequest) -> PresentationOutline:
    """Main entry: try Ollama LLM first, fallback to demo mode."""
    try:
        logger.info("ğŸš€ Attempting Ollama LLM outline generation")
        result = await generate_outline_with_llm(request)  # âŒ åªå˜—è©¦ 1 æ¬¡
        logger.info("âœ… LLM generation successful")
        return result
    except Exception as e:
        logger.error(f"âŒ LLM generation failed: {type(e).__name__}: {e}")
        import traceback
        logger.error(f"Stack trace:\n{traceback.format_exc()}")

    logger.warning("âš ï¸ Falling back to demo mode")  # âŒ ç«‹å³æ”¾æ£„
    return generate_outline_demo(request)
```

**å•é¡Œ**ï¼š
1. âŒ å¤±æ•—ä¸€æ¬¡å°±æ”¾æ£„
2. âŒ 33% è«‹æ±‚ä½¿ç”¨ä½å“è³ªçš„ demo mode
3. âŒ æ²’æœ‰å®¹éŒ¯æ©Ÿåˆ¶

---

### æ–¹æ¡ˆ A å¯¦ä½œï¼šç°¡å–®é‡è©¦

```python
import asyncio

async def generate_outline(request: GenerateRequest) -> PresentationOutline:
    """Main entry: try Ollama LLM with retry, fallback to demo mode."""
    max_retries = 3  # é…ç½®ï¼šæœ€å¤šå˜—è©¦æ¬¡æ•¸
    retry_delay = 1.0  # é…ç½®ï¼šé‡è©¦é–“éš”ï¼ˆç§’ï¼‰

    for attempt in range(1, max_retries + 1):
        try:
            logger.info(f"ğŸš€ Attempting Ollama LLM (å˜—è©¦ {attempt}/{max_retries})")
            result = await generate_outline_with_llm(request)
            logger.info(f"âœ… LLM generation successful on attempt {attempt}")
            return result  # âœ… æˆåŠŸç«‹å³è¿”å›

        except Exception as e:
            logger.warning(
                f"âš ï¸ Attempt {attempt}/{max_retries} failed: "
                f"{type(e).__name__}: {str(e)[:100]}"
            )

            # å¦‚æœä¸æ˜¯æœ€å¾Œä¸€æ¬¡ï¼Œç¹¼çºŒé‡è©¦
            if attempt < max_retries:
                logger.info(f"ğŸ”„ Retrying in {retry_delay}s... ({attempt + 1}/{max_retries})")
                await asyncio.sleep(retry_delay)
            else:
                # æœ€å¾Œä¸€æ¬¡å¤±æ•—ï¼Œè¨˜éŒ„å®Œæ•´éŒ¯èª¤
                logger.error(f"âŒ All {max_retries} attempts failed")
                import traceback
                logger.error(f"Final error stack trace:\n{traceback.format_exc()}")

    # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—ï¼Œä½¿ç”¨ demo mode
    logger.warning(
        f"âš ï¸ Falling back to demo mode after {max_retries} failed attempts"
    )
    return generate_outline_demo(request)
```

**æ”¹é€²é»**ï¼š
1. âœ… è‡ªå‹•é‡è©¦æœ€å¤š 3 æ¬¡
2. âœ… æ¯æ¬¡é‡è©¦é–“éš” 1 ç§’
3. âœ… è©³ç´°çš„æ—¥èªŒè¨˜éŒ„
4. âœ… æˆåŠŸç«‹å³è¿”å›
5. âœ… æœ€å¾Œæ‰ä½¿ç”¨ demo mode

---

### æ–¹æ¡ˆ B å¯¦ä½œï¼šæŒ‡æ•¸é€€é¿

```python
import asyncio

async def generate_outline(request: GenerateRequest) -> PresentationOutline:
    """Main entry: try Ollama LLM with exponential backoff, fallback to demo mode."""
    max_retries = 3
    base_delay = 1.0  # åŸºç¤å»¶é²

    for attempt in range(1, max_retries + 1):
        try:
            logger.info(f"ğŸš€ Attempting Ollama LLM (å˜—è©¦ {attempt}/{max_retries})")
            result = await generate_outline_with_llm(request)
            logger.info(f"âœ… LLM generation successful on attempt {attempt}")
            return result

        except Exception as e:
            logger.warning(
                f"âš ï¸ Attempt {attempt}/{max_retries} failed: "
                f"{type(e).__name__}: {str(e)[:100]}"
            )

            if attempt < max_retries:
                # æŒ‡æ•¸é€€é¿ï¼š1s, 2s, 4s
                delay = base_delay * (2 ** (attempt - 1))
                logger.info(f"ğŸ”„ Retrying in {delay}s... ({attempt + 1}/{max_retries})")
                await asyncio.sleep(delay)
            else:
                logger.error(f"âŒ All {max_retries} attempts failed")
                import traceback
                logger.error(f"Final error stack trace:\n{traceback.format_exc()}")

    logger.warning(
        f"âš ï¸ Falling back to demo mode after {max_retries} failed attempts"
    )
    return generate_outline_demo(request)
```

**æ”¹é€²é»**ï¼š
1. âœ… ç­‰å¾…æ™‚é–“éå¢ï¼š1 ç§’ â†’ 2 ç§’ â†’ 4 ç§’
2. âœ… é©æ‡‰æœå‹™å™¨è² è¼‰æ³¢å‹•
3. âœ… æ¸›å°‘é€£çºŒå¿«é€Ÿè«‹æ±‚

---

### æ–¹æ¡ˆ C å¯¦ä½œï¼šæ™ºèƒ½é‡è©¦

```python
import asyncio
from httpx import HTTPError, TimeoutException

# å¯é‡è©¦çš„éŒ¯èª¤é¡å‹
RETRIABLE_ERRORS = (
    ConnectionError,
    TimeoutException,
    HTTPError,
)

# ä¸å¯é‡è©¦çš„éŒ¯èª¤é¡å‹
NON_RETRIABLE_ERRORS = (
    ValueError,  # JSON è§£æéŒ¯èª¤
    KeyError,    # éŸ¿æ‡‰æ ¼å¼éŒ¯èª¤
    TypeError,   # é¡å‹éŒ¯èª¤
)

async def generate_outline(request: GenerateRequest) -> PresentationOutline:
    """Main entry: try Ollama LLM with intelligent retry, fallback to demo mode."""
    max_retries = 3
    retry_delay = 1.0

    for attempt in range(1, max_retries + 1):
        try:
            logger.info(f"ğŸš€ Attempting Ollama LLM (å˜—è©¦ {attempt}/{max_retries})")
            result = await generate_outline_with_llm(request)
            logger.info(f"âœ… LLM generation successful on attempt {attempt}")
            return result

        except NON_RETRIABLE_ERRORS as e:
            # ä¸å¯é‡è©¦çš„éŒ¯èª¤ï¼Œç›´æ¥æ”¾æ£„
            logger.error(
                f"âŒ Non-retriable error on attempt {attempt}: "
                f"{type(e).__name__}: {e}"
            )
            break  # ç›´æ¥è·³åˆ° demo mode

        except RETRIABLE_ERRORS as e:
            # å¯é‡è©¦çš„éŒ¯èª¤
            logger.warning(
                f"âš ï¸ Retriable error on attempt {attempt}/{max_retries}: "
                f"{type(e).__name__}: {str(e)[:100]}"
            )

            if attempt < max_retries:
                logger.info(f"ğŸ”„ Retrying in {retry_delay}s...")
                await asyncio.sleep(retry_delay)
            else:
                logger.error(f"âŒ All {max_retries} attempts failed")

        except Exception as e:
            # æœªçŸ¥éŒ¯èª¤ï¼Œä¿å®ˆè™•ç†ï¼ˆé‡è©¦ï¼‰
            logger.warning(
                f"âš ï¸ Unknown error on attempt {attempt}/{max_retries}: "
                f"{type(e).__name__}: {str(e)[:100]}"
            )

            if attempt < max_retries:
                await asyncio.sleep(retry_delay)

    logger.warning("âš ï¸ Falling back to demo mode")
    return generate_outline_demo(request)
```

**æ”¹é€²é»**ï¼š
1. âœ… æ ¹æ“šéŒ¯èª¤é¡å‹æ™ºèƒ½æ±ºç­–
2. âœ… é¿å…ç„¡æ„ç¾©çš„é‡è©¦
3. âœ… ç¯€çœè³‡æºå’Œæ™‚é–“

---

## é‹ä½œæµç¨‹

### æµç¨‹åœ–

```mermaid
graph TD
    A[ç”¨æˆ¶è«‹æ±‚] --> B[å˜—è©¦ 1: LLM èª¿ç”¨]
    B -->|66% æˆåŠŸ| C[âœ… è¿”å›çµæœ]
    B -->|34% å¤±æ•—| D[ç­‰å¾… 1 ç§’]
    D --> E[å˜—è©¦ 2: LLM èª¿ç”¨]
    E -->|66% æˆåŠŸ| C
    E -->|34% å¤±æ•—| F[ç­‰å¾… 1 ç§’]
    F --> G[å˜—è©¦ 3: LLM èª¿ç”¨]
    G -->|66% æˆåŠŸ| C
    G -->|34% å¤±æ•—| H[âŒ Demo Fallback]
```

### åŸ·è¡Œæ™‚åº

**æœ€ä½³æƒ…æ³ï¼ˆç¬¬ 1 æ¬¡æˆåŠŸï¼‰**ï¼š
```
0.0s: é–‹å§‹è«‹æ±‚
0.0s: å˜—è©¦ 1
5.0s: LLM è¿”å›æˆåŠŸ âœ…
ç¸½æ™‚é–“: 5 ç§’
```

**ä¸€èˆ¬æƒ…æ³ï¼ˆç¬¬ 2 æ¬¡æˆåŠŸï¼‰**ï¼š
```
0.0s: é–‹å§‹è«‹æ±‚
0.0s: å˜—è©¦ 1
5.0s: å¤±æ•—
5.0s: ç­‰å¾… 1 ç§’
6.0s: å˜—è©¦ 2
11.0s: LLM è¿”å›æˆåŠŸ âœ…
ç¸½æ™‚é–“: 11 ç§’
```

**æœ€å£æƒ…æ³ï¼ˆç¬¬ 3 æ¬¡æˆåŠŸï¼‰**ï¼š
```
0.0s: é–‹å§‹è«‹æ±‚
0.0s: å˜—è©¦ 1
5.0s: å¤±æ•—
5.0s: ç­‰å¾… 1 ç§’
6.0s: å˜—è©¦ 2
11.0s: å¤±æ•—
11.0s: ç­‰å¾… 1 ç§’
12.0s: å˜—è©¦ 3
17.0s: LLM è¿”å›æˆåŠŸ âœ…
ç¸½æ™‚é–“: 17 ç§’
```

**å…¨éƒ¨å¤±æ•—ï¼ˆDemo Modeï¼‰**ï¼š
```
0.0s: é–‹å§‹è«‹æ±‚
0.0s: å˜—è©¦ 1
5.0s: å¤±æ•—
5.0s: ç­‰å¾… 1 ç§’
6.0s: å˜—è©¦ 2
11.0s: å¤±æ•—
11.0s: ç­‰å¾… 1 ç§’
12.0s: å˜—è©¦ 3
17.0s: å¤±æ•—
17.0s: Demo Mode ç”Ÿæˆ
17.5s: è¿”å›çµæœ
ç¸½æ™‚é–“: 17.5 ç§’
```

---

## æ—¥èªŒç¯„ä¾‹

### æˆåŠŸæ¡ˆä¾‹ï¼ˆç¬¬ 1 æ¬¡ï¼‰

```log
2026-02-17 20:30:00 INFO ğŸš€ Attempting Ollama LLM (å˜—è©¦ 1/3)
2026-02-17 20:30:05 INFO ğŸ” Raw LLM response (first 500 chars): {"title":"é›¢æ•£æ•¸å­¸...
2026-02-17 20:30:05 INFO ğŸ” Parsed data type: <class 'dict'>
2026-02-17 20:30:05 INFO ğŸ” Dict keys: ['title', 'subtitle', 'slides']
2026-02-17 20:30:05 INFO âœ… LLM generation successful on attempt 1
```

### ç¬¬ 2 æ¬¡æˆåŠŸ

```log
2026-02-17 20:30:00 INFO ğŸš€ Attempting Ollama LLM (å˜—è©¦ 1/3)
2026-02-17 20:30:05 WARN âš ï¸ Attempt 1/3 failed: ValueError: Expected dict, got list
2026-02-17 20:30:05 INFO ğŸ”„ Retrying in 1.0s... (2/3)
2026-02-17 20:30:06 INFO ğŸš€ Attempting Ollama LLM (å˜—è©¦ 2/3)
2026-02-17 20:30:11 INFO ğŸ” Raw LLM response (first 500 chars): {"title":"é›¢æ•£æ•¸å­¸...
2026-02-17 20:30:11 INFO âœ… LLM generation successful on attempt 2
```

### å…¨éƒ¨å¤±æ•—ï¼ˆDemo Modeï¼‰

```log
2026-02-17 20:30:00 INFO ğŸš€ Attempting Ollama LLM (å˜—è©¦ 1/3)
2026-02-17 20:30:05 WARN âš ï¸ Attempt 1/3 failed: ValueError: Expected dict, got list
2026-02-17 20:30:05 INFO ğŸ”„ Retrying in 1.0s... (2/3)
2026-02-17 20:30:06 INFO ğŸš€ Attempting Ollama LLM (å˜—è©¦ 2/3)
2026-02-17 20:30:11 WARN âš ï¸ Attempt 2/3 failed: ValueError: Expected dict, got list
2026-02-17 20:30:11 INFO ğŸ”„ Retrying in 1.0s... (3/3)
2026-02-17 20:30:12 INFO ğŸš€ Attempting Ollama LLM (å˜—è©¦ 3/3)
2026-02-17 20:30:17 WARN âš ï¸ Attempt 3/3 failed: ValueError: Expected dict, got list
2026-02-17 20:30:17 ERROR âŒ All 3 attempts failed
2026-02-17 20:30:17 ERROR Final error stack trace:
Traceback (most recent call last):
  ...
2026-02-17 20:30:17 WARN âš ï¸ Falling back to demo mode after 3 failed attempts
2026-02-17 20:30:17 INFO Using demo mode for outline generation
```

---

## é…ç½®é¸é …

### ç’°å¢ƒè®Šæ•¸ï¼ˆå»ºè­°ï¼‰

```bash
# .env æ–‡ä»¶
LLM_MAX_RETRIES=3          # æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼ˆé è¨­ 3ï¼‰
LLM_RETRY_DELAY=1.0        # é‡è©¦å»¶é²ç§’æ•¸ï¼ˆé è¨­ 1.0ï¼‰
LLM_USE_EXPONENTIAL_BACKOFF=false  # æ˜¯å¦ä½¿ç”¨æŒ‡æ•¸é€€é¿ï¼ˆé è¨­ falseï¼‰
```

### ä»£ç¢¼é…ç½®

```python
# llm_service.py é–‹é ­
import os

# å¯é…ç½®çš„é‡è©¦åƒæ•¸
MAX_RETRIES = int(os.environ.get("LLM_MAX_RETRIES", "3"))
RETRY_DELAY = float(os.environ.get("LLM_RETRY_DELAY", "1.0"))
USE_EXPONENTIAL_BACKOFF = os.environ.get("LLM_USE_EXPONENTIAL_BACKOFF", "false").lower() == "true"
```

---

## æ€§èƒ½å½±éŸ¿

### éŸ¿æ‡‰æ™‚é–“åˆ†æ

| å ´æ™¯ | ç•¶å‰ï¼ˆç„¡é‡è©¦ï¼‰ | æ–¹æ¡ˆ Aï¼ˆç°¡å–®é‡è©¦ï¼‰ | æ–¹æ¡ˆ Bï¼ˆæŒ‡æ•¸é€€é¿ï¼‰ |
|------|---------------|------------------|------------------|
| **æœ€ä½³ï¼ˆ66%ï¼‰** | 5 ç§’ | 5 ç§’ | 5 ç§’ |
| **ç¬¬ 2 æ¬¡æˆåŠŸï¼ˆ22%ï¼‰** | - | 11 ç§’ | 12 ç§’ |
| **ç¬¬ 3 æ¬¡æˆåŠŸï¼ˆ7%ï¼‰** | - | 17 ç§’ | 19 ç§’ |
| **Demo Fallbackï¼ˆ3.9%ï¼‰** | 5 ç§’ | 17.5 ç§’ | 19.5 ç§’ |
| **å¹³å‡éŸ¿æ‡‰æ™‚é–“** | 5 ç§’ | **7.2 ç§’** | **7.8 ç§’** |

**çµè«–**ï¼š
- âœ… å¹³å‡åƒ…å¢åŠ  2.2 ç§’ï¼ˆ+44%ï¼‰
- âœ… æ›ä¾† 30% çš„æˆåŠŸç‡æå‡
- âœ… ç”¨æˆ¶é«”é©—å¤§å¹…æ”¹å–„ï¼ˆé«˜å“è³ªå…§å®¹ vs demoï¼‰

### è³‡æºæ¶ˆè€—

**API èª¿ç”¨æ¬¡æ•¸**ï¼š
- ç•¶å‰ï¼š1.0 æ¬¡/è«‹æ±‚
- é‡è©¦å¾Œï¼š1.44 æ¬¡/è«‹æ±‚ï¼ˆ+44%ï¼‰

**è¨ˆç®—**ï¼š
```
å¹³å‡èª¿ç”¨æ¬¡æ•¸ = 1Ã—0.66 + 2Ã—0.22 + 3Ã—0.12
            = 0.66 + 0.44 + 0.36
            = 1.46 æ¬¡
```

**æˆæœ¬åˆ†æ**ï¼š
- API èª¿ç”¨æˆæœ¬å¢åŠ ç´„ 46%
- ä½†æ›ä¾† 30% çš„æˆåŠŸç‡æå‡
- ROI éå¸¸é«˜

---

## æ¸¬è©¦è¨ˆåŠƒ

### å–®å…ƒæ¸¬è©¦

```python
import pytest
from unittest.mock import AsyncMock, patch

@pytest.mark.asyncio
async def test_retry_success_on_first_attempt():
    """æ¸¬è©¦ï¼šç¬¬ä¸€æ¬¡å˜—è©¦æˆåŠŸ"""
    request = GenerateRequest(text="test", num_slides=5)

    with patch('llm_service.generate_outline_with_llm') as mock_llm:
        mock_llm.return_value = PresentationOutline(...)

        result = await generate_outline(request)

        assert mock_llm.call_count == 1
        assert result is not None

@pytest.mark.asyncio
async def test_retry_success_on_second_attempt():
    """æ¸¬è©¦ï¼šç¬¬äºŒæ¬¡å˜—è©¦æˆåŠŸ"""
    request = GenerateRequest(text="test", num_slides=5)

    with patch('llm_service.generate_outline_with_llm') as mock_llm:
        mock_llm.side_effect = [
            ValueError("First attempt fails"),
            PresentationOutline(...)  # Second attempt succeeds
        ]

        result = await generate_outline(request)

        assert mock_llm.call_count == 2
        assert result is not None

@pytest.mark.asyncio
async def test_retry_all_attempts_fail():
    """æ¸¬è©¦ï¼šæ‰€æœ‰å˜—è©¦éƒ½å¤±æ•—ï¼Œä½¿ç”¨ demo mode"""
    request = GenerateRequest(text="test", num_slides=5)

    with patch('llm_service.generate_outline_with_llm') as mock_llm:
        with patch('llm_service.generate_outline_demo') as mock_demo:
            mock_llm.side_effect = ValueError("Always fails")
            mock_demo.return_value = PresentationOutline(...)

            result = await generate_outline(request)

            assert mock_llm.call_count == 3  # Tried 3 times
            assert mock_demo.call_count == 1  # Fell back to demo
            assert result is not None
```

### æ•´åˆæ¸¬è©¦

```python
@pytest.mark.asyncio
async def test_retry_with_real_llm():
    """æ•´åˆæ¸¬è©¦ï¼šçœŸå¯¦ LLM ç’°å¢ƒ"""
    request = GenerateRequest(
        text="åœ–è«–æ˜¯æ•¸å­¸çš„ä¸€å€‹åˆ†æ”¯...",
        num_slides=8,
        language="zh-TW",
        style="professional"
    )

    result = await generate_outline(request)

    # é©—è­‰çµæœ
    assert result.title is not None
    assert len(result.slides) == 8
    assert all(slide.title for slide in result.slides)
```

### è² è¼‰æ¸¬è©¦

```python
import asyncio

async def load_test_retry_mechanism():
    """è² è¼‰æ¸¬è©¦ï¼š100 å€‹ä¸¦ç™¼è«‹æ±‚"""
    requests = [
        GenerateRequest(text=f"Test {i}", num_slides=5)
        for i in range(100)
    ]

    start_time = time.time()
    results = await asyncio.gather(*[
        generate_outline(req) for req in requests
    ])
    duration = time.time() - start_time

    success_count = sum(1 for r in results if not is_demo_mode(r))
    print(f"Success rate: {success_count}/100 = {success_count}%")
    print(f"Total time: {duration:.2f}s")
    print(f"Avg time per request: {duration/100:.2f}s")
```

---

## ç›£æ§æŒ‡æ¨™

### é—œéµæŒ‡æ¨™ï¼ˆKPIï¼‰

1. **LLM æˆåŠŸç‡**
   - å®šç¾©ï¼šLLM èª¿ç”¨æˆåŠŸçš„è«‹æ±‚æ¯”ä¾‹
   - ç›®æ¨™ï¼šâ‰¥ 95%
   - è¨ˆç®—ï¼šæˆåŠŸæ¬¡æ•¸ / ç¸½è«‹æ±‚æ•¸

2. **å¹³å‡é‡è©¦æ¬¡æ•¸**
   - å®šç¾©ï¼šæ¯å€‹è«‹æ±‚å¹³å‡èª¿ç”¨ LLM çš„æ¬¡æ•¸
   - ç›®æ¨™ï¼šâ‰¤ 1.5 æ¬¡
   - è¨ˆç®—ï¼šç¸½èª¿ç”¨æ¬¡æ•¸ / ç¸½è«‹æ±‚æ•¸

3. **Demo Fallback ç‡**
   - å®šç¾©ï¼šæœ€çµ‚ä½¿ç”¨ demo mode çš„è«‹æ±‚æ¯”ä¾‹
   - ç›®æ¨™ï¼šâ‰¤ 5%
   - è¨ˆç®—ï¼šdemo æ¬¡æ•¸ / ç¸½è«‹æ±‚æ•¸

4. **å¹³å‡éŸ¿æ‡‰æ™‚é–“**
   - å®šç¾©ï¼šå¾è«‹æ±‚åˆ°è¿”å›çš„å¹³å‡æ™‚é–“
   - ç›®æ¨™ï¼šâ‰¤ 8 ç§’
   - è¨ˆç®—ï¼šç¸½éŸ¿æ‡‰æ™‚é–“ / ç¸½è«‹æ±‚æ•¸

### æ—¥èªŒç›£æ§

```python
# åœ¨æ¯æ¬¡æˆåŠŸ/å¤±æ•—æ™‚è¨˜éŒ„æŒ‡æ¨™
logger.info(f"METRIC: llm_success_rate={success_rate:.2f}")
logger.info(f"METRIC: avg_retry_count={avg_retries:.2f}")
logger.info(f"METRIC: demo_fallback_rate={demo_rate:.2f}")
logger.info(f"METRIC: avg_response_time={avg_time:.2f}s")
```

### Prometheus æŒ‡æ¨™ï¼ˆå¯é¸ï¼‰

```python
from prometheus_client import Counter, Histogram

# å®šç¾©æŒ‡æ¨™
llm_attempts = Counter('llm_attempts_total', 'Total LLM attempts')
llm_successes = Counter('llm_successes_total', 'Successful LLM calls')
llm_failures = Counter('llm_failures_total', 'Failed LLM calls')
demo_fallbacks = Counter('demo_fallbacks_total', 'Demo mode fallbacks')
response_time = Histogram('response_time_seconds', 'Response time')

# åœ¨ä»£ç¢¼ä¸­è¨˜éŒ„
llm_attempts.inc()
llm_successes.inc()  # æˆ– llm_failures.inc()
response_time.observe(duration)
```

---

## éƒ¨ç½²å»ºè­°

### éšæ®µå¼éƒ¨ç½²

**éšæ®µ 1ï¼šé–‹ç™¼ç’°å¢ƒæ¸¬è©¦**ï¼ˆ1 å¤©ï¼‰
- å¯¦ä½œæ–¹æ¡ˆ Aï¼ˆç°¡å–®é‡è©¦ï¼‰
- å–®å…ƒæ¸¬è©¦ + æ•´åˆæ¸¬è©¦
- é©—è­‰åŠŸèƒ½æ­£ç¢ºæ€§

**éšæ®µ 2ï¼šç°åº¦ç™¼å¸ƒ**ï¼ˆ3-7 å¤©ï¼‰
- 10% æµé‡ä½¿ç”¨é‡è©¦æ©Ÿåˆ¶
- ç›£æ§æˆåŠŸç‡å’ŒéŸ¿æ‡‰æ™‚é–“
- æ”¶é›†ç”¨æˆ¶åé¥‹

**éšæ®µ 3ï¼šå…¨é‡ç™¼å¸ƒ**ï¼ˆæŒçºŒï¼‰
- 100% æµé‡ä½¿ç”¨é‡è©¦
- æŒçºŒç›£æ§æŒ‡æ¨™
- æ ¹æ“šæ•¸æ“šå„ªåŒ–åƒæ•¸

### å›æ»¾è¨ˆåŠƒ

**è§¸ç™¼æ¢ä»¶**ï¼š
- å¹³å‡éŸ¿æ‡‰æ™‚é–“ > 10 ç§’
- LLM æˆåŠŸç‡ < 80%
- éŒ¯èª¤ç‡ > 10%

**å›æ»¾æ­¥é©Ÿ**ï¼š
1. åœæ­¢æ–°ç‰ˆæœ¬éƒ¨ç½²
2. åˆ‡æ›å›èˆŠç‰ˆæœ¬ä»£ç¢¼
3. ç›£æ§ç³»çµ±æ¢å¾©
4. åˆ†æå•é¡Œæ ¹å› 

---

## ç¸½çµ

### å¯¦ä½œå»ºè­°

**æ¨è–¦æ–¹æ¡ˆ**ï¼šæ–¹æ¡ˆ Aï¼ˆç°¡å–®é‡è©¦ï¼‰
- âœ… å¯¦ä½œç°¡å–®ï¼ˆ15 è¡Œä»£ç¢¼ï¼‰
- âœ… æ•ˆæœé¡¯è‘—ï¼ˆ+30% æˆåŠŸç‡ï¼‰
- âœ… é¢¨éšªä½
- âœ… æ˜“æ–¼ç¶­è­·

**å¯¦ä½œå„ªå…ˆç´š**ï¼š
1. ğŸ”´ **é«˜å„ªå…ˆç´š**ï¼šå¯¦ä½œæ–¹æ¡ˆ A
2. ğŸŸ¡ **ä¸­å„ªå…ˆç´š**ï¼šæ·»åŠ ç›£æ§æŒ‡æ¨™
3. ğŸŸ¢ **ä½å„ªå…ˆç´š**ï¼šè€ƒæ…®æ–¹æ¡ˆ B/C

### é æœŸæ•ˆæœ

**æˆåŠŸç‡æå‡**ï¼š
- ç•¶å‰ï¼š66%
- ç›®æ¨™ï¼š**96%**
- æå‡ï¼š**+30%**

**ç”¨æˆ¶é«”é©—**ï¼š
- Demo Fallbackï¼š34% â†’ **3.6%**
- é«˜å“è³ªå…§å®¹æ¯”ä¾‹ï¼šå¤§å¹…æå‡

**æˆæœ¬**ï¼š
- API èª¿ç”¨å¢åŠ ï¼š+46%
- éŸ¿æ‡‰æ™‚é–“å¢åŠ ï¼š+2.2 ç§’
- ROIï¼šéå¸¸é«˜

### ä¸‹ä¸€æ­¥è¡Œå‹•

1. âœ… **ç«‹å³å¯¦ä½œ**ï¼šæ–¹æ¡ˆ A ç°¡å–®é‡è©¦
2. ğŸ“Š **éƒ¨ç½²å¾Œ**ï¼šç›£æ§æŒ‡æ¨™ä¸¦èª¿å„ª
3. ğŸ”„ **æŒçºŒå„ªåŒ–**ï¼šæ ¹æ“šæ•¸æ“šæ”¹é€²åƒæ•¸

---

## é™„éŒ„

### ç›¸é—œæ–‡ä»¶

- [SYSTEM_PROMPT_æ¸¬è©¦çµæœ.md](SYSTEM_PROMPT_æ¸¬è©¦çµæœ.md)
- [JSON_vs_Markdown_åˆ†æçµæœ.md](JSON_vs_Markdown_åˆ†æçµæœ.md)
- [ç°¡å ±å…§å®¹æ“´å……æç¤ºåˆ†æ.md](ç°¡å ±å…§å®¹æ“´å……æç¤ºåˆ†æ.md)

### åƒè€ƒè³‡æ–™

- [Exponential Backoff Algorithm](https://en.wikipedia.org/wiki/Exponential_backoff)
- [Circuit Breaker Pattern](https://martinfowler.com/bliki/CircuitBreaker.html)
- [Retry Pattern - Microsoft](https://docs.microsoft.com/en-us/azure/architecture/patterns/retry)

### è®Šæ›´æ­·å²

| ç‰ˆæœ¬ | æ—¥æœŸ | ä½œè€… | è®Šæ›´å…§å®¹ |
|------|------|------|---------|
| 1.0 | 2026-02-17 | Claude | åˆå§‹ç‰ˆæœ¬ |
