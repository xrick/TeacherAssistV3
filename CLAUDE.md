# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

TXT2PPTX: A web application that converts plain text into structured PowerPoint presentations using LLM-generated outlines. The UI is in Traditional Chinese (zh-TW).

## Commands

```bash
# Activate virtual environment
source pptxenv/bin/activate

# Start server (from txt2pptx/)
cd txt2pptx && bash start.sh

# Stop server
cd txt2pptx && bash stop.sh

# Manual start (from repo root)
cd txt2pptx && python -m uvicorn backend.main:app --host 0.0.0.0 --port 8000 --reload

# Health check
curl http://localhost:8000/api/health

# Install dependencies (no requirements.txt yet â€” install manually)
pip install fastapi uvicorn python-pptx pydantic httpx
```

## Environment Variables

- `OLLAMA_URL` â€” Ollama server address (default: `http://localhost:11434`)
- `OLLAMA_MODEL` â€” Model name (default: `gpt-oss:2b`). The local machine only has `gpt-oss:20b` installed, so start with `OLLAMA_MODEL=gpt-oss:20b bash start.sh`
- `PORT` â€” Uvicorn port (default: `8000`), used by start.sh/stop.sh

## Architecture

The app lives entirely in `txt2pptx/` with a 3-stage pipeline:

```
User text â†’ [LLM Outline Generation] â†’ [PPTX Builder] â†’ .pptx file
                 llm_service.py          pptx_generator.py
```

### Backend (`txt2pptx/backend/`)

- **main.py** â€” FastAPI app. Routes: `POST /api/generate`, `GET /api/download/{filename}`, `GET /api/health`. Serves frontend static files from `/`. Output PPTX files are saved to `txt2pptx/generated/{uuid8}.pptx`.
- **models.py** â€” Pydantic v2 models. `GenerateRequest` (text, num_slides, language, style), `PresentationOutline` / `SlideData` (intermediate), `GenerateResponse` (output). `SlideLayout` enum defines 9 layout types: TITLE, SECTION, BULLETS, TWO_COLUMN, IMAGE_LEFT, IMAGE_RIGHT, KEY_STATS, COMPARISON, CONCLUSION.
- **llm_service.py** â€” Calls Ollama's OpenAI-compatible API (`/v1/chat/completions`) via `httpx`. `generate_outline()` is the entry point: tries LLM first, falls back to `generate_outline_demo()` (heuristic text-splitting) if Ollama is unavailable. Timeout is 600s for CPU-only inference. The `SYSTEM_PROMPT` is a long Chinese prompt that constrains LLM output to strict JSON matching the `PresentationOutline` schema â€” first slide must be title_slide, last must be conclusion, bullets limited to 3-5 per slide.
- **pptx_generator.py** â€” Builds PPTX using `python-pptx`. All slides are **code-drawn** (no .pptx template file): starts from `Presentation()` blank, uses `slide_layouts[6]` (Blank), and positions every element via hardcoded Inches coordinates (~460 lines). A `BUILDERS` dict maps each `SlideLayout` enum to a builder function. `Theme` class holds the Ocean Gradient color scheme (primary `#065A82`, accent `#02C39A`) and Calibri fonts.

### Frontend (`txt2pptx/frontend/`)

Vanilla HTML/CSS/JS (no build step). `app.js` calls `/api/generate`, shows progress simulation, renders outline preview, and provides download link. Keyboard shortcut: Ctrl+Enter to generate.

### Key Data Flow

1. Frontend POSTs `{text, num_slides, language, style}` to `/api/generate`
2. `llm_service.generate_outline()` sends text + SYSTEM_PROMPT to Ollama, parses JSON response into `PresentationOutline`
3. `pptx_generator.generate_pptx()` iterates `outline.slides`, dispatches each to a layout-specific builder via `BUILDERS` dict
4. PPTX bytes saved to `txt2pptx/generated/`, filename returned to frontend

### PPTX Generation â€” Code-Drawn Design

The current architecture does **not** use .pptx template files. All 9 slide types are drawn programmatically:

- Background colors via `_set_slide_bg()`
- Shapes (rectangles, ovals) via `_add_shape()`
- Text boxes with manual positioning via `_add_text_box()`
- Bullet lists with custom XML markers via `_add_bullets()`
- Image areas are gray placeholder rectangles (no real image insertion)
- A template file `txt2pptx/templates/ocean_gradient.pptx` has been created for future migration to template-based generation
- See `claudedocs/how_to/pptx_template_guide.md` for migration analysis toward template-based approach

### LLM Integration

Uses Ollama's OpenAI-compatible endpoint (`/v1/chat/completions`), **not** the native `/api/chat`. Response parsing strips markdown fences before `json.loads()`. When Ollama is unreachable, the demo fallback splits input text into paragraphs and distributes across slides with rotating layouts.

## Project Structure

```text
txt2pptx/
  backend/           # FastAPI + python-pptx
  frontend/          # Vanilla HTML/CSS/JS (no build step)
  generated/         # Output PPTX files (auto-created, gitignored ideally)
  templates/         # .pptx template files (ocean_gradient.pptx)
  start.sh / stop.sh # Server lifecycle scripts (PID-managed)
claudedocs/          # Claude-generated analysis & documentation
  how_to/            # Template guides, Google Slides workflow docs
refData/             # Reference materials, papers, plans
pptxenv/             # Python virtual environment (not in git)
```

## Tech Stack

- Python 3.11, FastAPI, Uvicorn, httpx, python-pptx, Pydantic v2
- No test framework configured yet
- No linter/formatter configured yet
- No requirements.txt yet â€” dependencies listed in start.sh error message

---

## Recent Updates

### 2026-02-17: Speaker Notes å“è³ªå„ªåŒ–èˆ‡é‡è©¦æ©Ÿåˆ¶å¯¦ä½œ

**å®Œæˆé …ç›®**:

1. âœ… **é‡è©¦æ©Ÿåˆ¶å¯¦ä½œ** - 3 æ¬¡é‡è©¦ï¼Œ100% LLM æˆåŠŸç‡
2. âœ… **æ¨¡æ¿ UI å„ªåŒ–** - 8 å€‹ä¸­æ–‡æ¨¡æ¿åç¨±é¡¯ç¤º
3. âœ… **Speaker Notes å“è³ªæå‡** - å¾ 18.1 å­— â†’ 72.4 å­— (100% é”æ¨™)

#### 1. é‡è©¦æ©Ÿåˆ¶ (LLM Retry Logic)

**å¯¦ä½œä½ç½®**: [txt2pptx/backend/llm_service.py](txt2pptx/backend/llm_service.py)

**ç’°å¢ƒè®Šæ•¸**:

- `LLM_MAX_RETRIES=3` - æœ€å¤§é‡è©¦æ¬¡æ•¸
- `LLM_RETRY_DELAY=1.0` - é‡è©¦é–“éš”ï¼ˆç§’ï¼‰

**æ¸¬è©¦çµæœ**:

```text
ç¸½æ¸¬è©¦æ¬¡æ•¸: 10
LLM æˆåŠŸ: 10/10 (100%)
Demo Fallback: 0/10 (0%)
å¹³å‡éŸ¿æ‡‰æ™‚é–“: 78.1 ç§’
```

**é—œéµä»£ç¢¼**:
```python
MAX_RETRIES = int(os.environ.get("LLM_MAX_RETRIES", "3"))
RETRY_DELAY = float(os.environ.get("LLM_RETRY_DELAY", "1.0"))

for attempt in range(1, MAX_RETRIES + 1):
    try:
        logger.info(f"ğŸš€ Attempting Ollama LLM (å˜—è©¦ {attempt}/{MAX_RETRIES})")
        result = await generate_outline_with_llm(request)
        logger.info(f"âœ… LLM generation successful on attempt {attempt}")
        return result
    except Exception as e:
        if attempt < MAX_RETRIES:
            logger.info(f"ğŸ”„ Retrying in {RETRY_DELAY}s...")
            await asyncio.sleep(RETRY_DELAY)
```

#### 2. æ¨¡æ¿ UI å„ªåŒ–

**å¯¦ä½œä½ç½®**: [txt2pptx/backend/main.py:92-127](txt2pptx/backend/main.py#L92-L127)

**8 å€‹æ¨¡æ¿åŠä¸­æ–‡åç¨±**:

- `College_Elegance` â†’ å­¸é™¢å…¸é›…
- `Data_Centric` â†’ æ•¸æ“šå°å‘
- `High_Contrast` â†’ é«˜èª¿å°æ¯”
- `Minimalist_Corporate` â†’ æ¥µç°¡å•†å‹™
- `Modernist` â†’ æ‘©ç™»ç¾ä»£
- `ocean_gradient` â†’ é è¨­ç‰ˆé¢
- `Startup_Edge` â†’ æ–°å‰µæ´»åŠ›
- `Zen_Serenity` â†’ éœè¬ç¦ªæ„

**API ç«¯é»**: `GET /api/templates` è¿”å›åŒ…å«ä¸­æ–‡åç¨±çš„æ¨¡æ¿åˆ—è¡¨

#### 3. Speaker Notes å“è³ªå„ªåŒ– ğŸ¯

**å•é¡Œè¨ºæ–·**:

- åˆå§‹ç‹€æ…‹: Notes å¹³å‡é•·åº¦ 18.1 å­—ï¼Œä¸ç¬¦åˆæ•™å­¸éœ€æ±‚
- æ ¹æœ¬åŸå› : SYSTEM_PROMPT èªªã€Œå»ºè­°ã€ï¼ŒPydantic schema èªªã€ŒOptionalã€

**è§£æ±ºæ–¹æ¡ˆ**:

**A. SYSTEM_PROMPT çµæ§‹åŒ–** ([llm_service.py:48-54](txt2pptx/backend/llm_service.py#L48-L54)):

```python
- speaker_notesï¼š**æ¯é å¿…é ˆæä¾› 50-100 å­—çš„è©³ç´°è£œå……èªªæ˜**ï¼ŒåŒ…å«ï¼š
  â€¢ èƒŒæ™¯è³‡è¨Šå’Œè„ˆçµ¡èªªæ˜ï¼ˆ10-20 å­—ï¼‰
  â€¢ é‡é»å…§å®¹çš„å»¶ä¼¸è§£é‡‹ï¼ˆ20-30 å­—ï¼‰
  â€¢ å¯¦ä¾‹æˆ–æ‡‰ç”¨å ´æ™¯ï¼ˆ20-30 å­—ï¼‰
  â€¢ å¼•å°è¨è«–çš„å•é¡Œæˆ–æ€è€ƒé»ï¼ˆ10-20 å­—ï¼‰
```

**B. Pydantic å¼·åˆ¶ç´„æŸ** ([models.py:36](txt2pptx/backend/models.py#L36)):
```python
# ä¿®æ”¹å‰
speaker_notes: Optional[str] = None

# ä¿®æ”¹å¾Œ
speaker_notes: str = Field(
    default="",
    min_length=50,      # ğŸ¯ é—œéµç´„æŸ
    max_length=200,
    description="è©³ç´°è£œå……èªªæ˜ï¼Œ50-100å­—ç‚ºä½³"
)
```

**æœ€çµ‚æ¸¬è©¦çµæœ** (College_Elegance æ¨¡æ¿):

```text
âœ… Bullet é•·åº¦: 25.3 å­— (ç›®æ¨™: â‰¥ 15 å­—)
âœ… Speaker notes è¦†è“‹ç‡: 10/10 (100%)
âœ… Speaker notes å¹³å‡é•·åº¦: 72.4 å­— (ç›®æ¨™: â‰¥ 50 å­—) ğŸ‰
âœ… Layout å¤šæ¨£æ€§: 5 ç¨® (bullets, key_stats, section_header, title_slide, two_column)
âœ… é Demo Mode: æ˜¯
âœ… PPTX ä¸‹è¼‰: æˆåŠŸ

å“è³ªè¦†è“‹ç‡: 100% (6/6) ğŸ‰
```

**æ”¹é€²æ­·ç¨‹**:

| éšæ®µ | Notes è¦†è“‹ç‡ | Notes é•·åº¦ | å“è³ªé€šéç‡ |
|------|--------------|------------|------------|
| åˆå§‹ | 100% | 18.1 å­— âŒ | 66.7% |
| SYSTEM_PROMPT å„ªåŒ– | 0% âŒ | 0 å­— | 50.0% |
| Pydantic min=30 | 100% | 46.0 å­— âš ï¸ | 50.0% |
| **Pydantic min=50** | **100%** | **72.4 å­—** âœ… | **100%** âœ… |

**é—œéµæ´å¯Ÿ**:

- **Pydantic schema > SYSTEM_PROMPT**: ç¡¬ç´„æŸå„ªå…ˆæ–¼è»Ÿå¼•å°
- **LLM è¡Œç‚ºæ¨¡å¼**: ç”Ÿæˆé•·åº¦ â‰ˆ `min_length Ã— 1.5`
- **çµæ§‹åŒ–å¼•å°**: 4 é …å…§å®¹è¦æ±‚å¹«åŠ© LLM ç”Ÿæˆå¤šå±¤æ¬¡å…§å®¹

#### æ¸¬è©¦æ¡†æ¶

**æ•´åˆæ¸¬è©¦**: [test/test_integration_template.py](test/test_integration_template.py)

- æ¸¬è©¦å…§å®¹: test/Discrete_mathematics.txt (2908 å­—å…ƒ)
- å“è³ªæª¢æŸ¥: 6 é …æŒ‡æ¨™ï¼ˆbullet é•·åº¦ã€notes è¦†è“‹ç‡ã€notes é•·åº¦ã€layout å¤šæ¨£æ€§ã€demo åµæ¸¬ã€ä¸‹è¼‰æˆåŠŸï¼‰
- æ¨¡æ¿æ”¯æŒ: å¯æŒ‡å®šä»»æ„æ¨¡æ¿é€²è¡Œæ¸¬è©¦

**é‡è©¦æ©Ÿåˆ¶æ¸¬è©¦**: [test/test_retry_mechanism.py](test/test_retry_mechanism.py)

- 10 æ¬¡é€£çºŒæ¸¬è©¦ï¼Œé©—è­‰æˆåŠŸç‡
- å“è³ªè©•åˆ†: 4 é …æŒ‡æ¨™ï¼ˆbullet é•·åº¦ã€notes è¦†è“‹ç‡ã€notes é•·åº¦ã€layout å¤šæ¨£æ€§ï¼‰

#### ç›¸é—œæ–‡æª”

- [é–‹ç™¼æ—¥èªŒ - 2026-02-17](claudedocs/dev_diary/2026-02-17_speaker_notes_optimization.md) - å®Œæ•´æŠ€è¡“åˆ†æ
- [Notes è¦†è“‹ç‡æŒ‡æ¨™èªªæ˜](claudedocs/Notesè¦†è“‹ç‡æŒ‡æ¨™èªªæ˜.md) - æŒ‡æ¨™å®šç¾©èˆ‡è¨ˆç®—
- [é‡è©¦æ©Ÿåˆ¶å¯¦ä½œç¸½çµ](claudedocs/é‡è©¦æ©Ÿåˆ¶å¯¦ä½œç¸½çµ.md) - é‡è©¦ç­–ç•¥èˆ‡æ¸¬è©¦çµæœ

#### æ€§èƒ½æŒ‡æ¨™

- LLM æˆåŠŸç‡: **100%** (10/10 æ¸¬è©¦)
- Speaker Notes é•·åº¦: **72.4 å­—** (144% é”æ¨™)
- å“è³ªè¦†è“‹ç‡: **100%** (6/6 æª¢æŸ¥)
- éŸ¿æ‡‰æ™‚é–“: 86.9 ç§’ï¼ˆå« 1 æ¬¡é‡è©¦ï¼‰
- Layout å¤šæ¨£æ€§: **5 ç¨®** (è¶…éç›®æ¨™)
